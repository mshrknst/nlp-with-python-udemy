{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 27,\n",
       " '?': 12,\n",
       " 'apple': 33,\n",
       " 'back': 32,\n",
       " 'bathroom': 21,\n",
       " 'bedroom': 3,\n",
       " 'daniel': 14,\n",
       " 'discarded': 28,\n",
       " 'down': 16,\n",
       " 'dropped': 25,\n",
       " 'football': 10,\n",
       " 'garden': 2,\n",
       " 'got': 20,\n",
       " 'grabbed': 7,\n",
       " 'hallway': 36,\n",
       " 'in': 37,\n",
       " 'is': 24,\n",
       " 'john': 11,\n",
       " 'journeyed': 4,\n",
       " 'kitchen': 26,\n",
       " 'left': 29,\n",
       " 'mary': 1,\n",
       " 'milk': 35,\n",
       " 'moved': 8,\n",
       " 'no': 30,\n",
       " 'office': 34,\n",
       " 'picked': 13,\n",
       " 'put': 22,\n",
       " 'sandra': 31,\n",
       " 'the': 5,\n",
       " 'there': 19,\n",
       " 'to': 6,\n",
       " 'took': 9,\n",
       " 'travelled': 18,\n",
       " 'up': 23,\n",
       " 'went': 17,\n",
       " 'yes': 15}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  5,  3, 27],\n",
       "       [ 0,  0,  0, ...,  5,  2, 27],\n",
       "       [ 0,  0,  0, ...,  5,  2, 27],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  5, 33, 27],\n",
       "       [ 0,  0,  0, ...,  5,  2, 27],\n",
       "       [ 0,  0,  0, ..., 33, 19, 27]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 11, 37,  5, 26, 12],\n",
       "       [24, 11, 37,  5, 26, 12],\n",
       "       [24, 11, 37,  5,  2, 12],\n",
       "       ...,\n",
       "       [24,  1, 37,  5,  3, 12],\n",
       "       [24, 31, 37,  5,  2, 12],\n",
       "       [24,  1, 37,  5,  2, 12]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.8770 - acc: 0.5007 - val_loss: 0.6940 - val_acc: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 4s 368us/step - loss: 0.7029 - acc: 0.4987 - val_loss: 0.6938 - val_acc: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.6960 - acc: 0.4971 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.6951 - acc: 0.4988 - val_loss: 0.6940 - val_acc: 0.5030\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.6947 - acc: 0.4969 - val_loss: 0.6935 - val_acc: 0.5030\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.6949 - acc: 0.4903 - val_loss: 0.6945 - val_acc: 0.4970\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.6947 - acc: 0.4940 - val_loss: 0.6938 - val_acc: 0.4970\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.6944 - acc: 0.5030 - val_loss: 0.6935 - val_acc: 0.4790\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.6940 - acc: 0.4990 - val_loss: 0.6937 - val_acc: 0.4870\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.6940 - acc: 0.5008 - val_loss: 0.6938 - val_acc: 0.4780\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 4s 366us/step - loss: 0.6927 - acc: 0.5148 - val_loss: 0.6942 - val_acc: 0.4950\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.6919 - acc: 0.5199 - val_loss: 0.6926 - val_acc: 0.4890\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.6878 - acc: 0.5379 - val_loss: 0.6836 - val_acc: 0.5540\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.6721 - acc: 0.5862 - val_loss: 0.6566 - val_acc: 0.6370\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.6521 - acc: 0.6156 - val_loss: 0.6352 - val_acc: 0.6350\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.6373 - acc: 0.6415 - val_loss: 0.6219 - val_acc: 0.6580\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.6306 - acc: 0.6465 - val_loss: 0.6120 - val_acc: 0.6750\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.6143 - acc: 0.6706 - val_loss: 0.5912 - val_acc: 0.6990\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.5939 - acc: 0.6995 - val_loss: 0.5679 - val_acc: 0.7220\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.5660 - acc: 0.7135 - val_loss: 0.5542 - val_acc: 0.7450\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.5472 - acc: 0.7354 - val_loss: 0.5316 - val_acc: 0.7530\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 4s 367us/step - loss: 0.5323 - acc: 0.7437 - val_loss: 0.5245 - val_acc: 0.7490\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.5132 - acc: 0.7613 - val_loss: 0.5189 - val_acc: 0.7480\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.5035 - acc: 0.7682 - val_loss: 0.4882 - val_acc: 0.7770\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.4871 - acc: 0.7796 - val_loss: 0.4838 - val_acc: 0.7870\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.4716 - acc: 0.7916 - val_loss: 0.4775 - val_acc: 0.7930\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.4564 - acc: 0.7979 - val_loss: 0.4580 - val_acc: 0.7830\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.4507 - acc: 0.8035 - val_loss: 0.4582 - val_acc: 0.8020\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.4417 - acc: 0.8105 - val_loss: 0.4473 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.4267 - acc: 0.8205 - val_loss: 0.4458 - val_acc: 0.8110\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.4134 - acc: 0.8237 - val_loss: 0.4338 - val_acc: 0.8040\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.4076 - acc: 0.8287 - val_loss: 0.4251 - val_acc: 0.8100\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.3924 - acc: 0.8376 - val_loss: 0.4168 - val_acc: 0.8150\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 4s 366us/step - loss: 0.3918 - acc: 0.8361 - val_loss: 0.4392 - val_acc: 0.8210\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.3827 - acc: 0.8382 - val_loss: 0.4103 - val_acc: 0.8270\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.3761 - acc: 0.8383 - val_loss: 0.4081 - val_acc: 0.8300\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.3696 - acc: 0.8434 - val_loss: 0.4226 - val_acc: 0.8260\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.3651 - acc: 0.8462 - val_loss: 0.3957 - val_acc: 0.8250\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.3631 - acc: 0.8423 - val_loss: 0.4038 - val_acc: 0.8290\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.3554 - acc: 0.8477 - val_loss: 0.4086 - val_acc: 0.8290\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.3543 - acc: 0.8472 - val_loss: 0.4073 - val_acc: 0.8280\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.3520 - acc: 0.8483 - val_loss: 0.4035 - val_acc: 0.8320\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.3463 - acc: 0.8509 - val_loss: 0.3857 - val_acc: 0.8290\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.3474 - acc: 0.8501 - val_loss: 0.3884 - val_acc: 0.8350\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 4s 367us/step - loss: 0.3400 - acc: 0.8544 - val_loss: 0.3964 - val_acc: 0.8290\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 4s 367us/step - loss: 0.3404 - acc: 0.8494 - val_loss: 0.4036 - val_acc: 0.8370\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 4s 367us/step - loss: 0.3407 - acc: 0.8518 - val_loss: 0.3913 - val_acc: 0.8350\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.3378 - acc: 0.8525 - val_loss: 0.3990 - val_acc: 0.8310\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 4s 366us/step - loss: 0.3344 - acc: 0.8529 - val_loss: 0.3983 - val_acc: 0.8240\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 4s 367us/step - loss: 0.3335 - acc: 0.8595 - val_loss: 0.4164 - val_acc: 0.8200\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.3296 - acc: 0.8552 - val_loss: 0.4031 - val_acc: 0.8280\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 4s 366us/step - loss: 0.3255 - acc: 0.8581 - val_loss: 0.3999 - val_acc: 0.8260\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.3221 - acc: 0.8599 - val_loss: 0.4078 - val_acc: 0.8290\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 4s 366us/step - loss: 0.3199 - acc: 0.8609 - val_loss: 0.3930 - val_acc: 0.8240\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 4s 368us/step - loss: 0.3129 - acc: 0.8651 - val_loss: 0.3764 - val_acc: 0.8280\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3065 - acc: 0.8673 - val_loss: 0.3971 - val_acc: 0.8410\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.3076 - acc: 0.8679 - val_loss: 0.4035 - val_acc: 0.8150\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.3010 - acc: 0.8718 - val_loss: 0.3808 - val_acc: 0.8390\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.3021 - acc: 0.8689 - val_loss: 0.4005 - val_acc: 0.8370\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2983 - acc: 0.8716 - val_loss: 0.3891 - val_acc: 0.8330\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.3006 - acc: 0.8701 - val_loss: 0.3953 - val_acc: 0.8310\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2993 - acc: 0.8744 - val_loss: 0.3907 - val_acc: 0.8410\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.2972 - acc: 0.8713 - val_loss: 0.3849 - val_acc: 0.8360\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2981 - acc: 0.8731 - val_loss: 0.3912 - val_acc: 0.8360\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2934 - acc: 0.8740 - val_loss: 0.4026 - val_acc: 0.8310\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2895 - acc: 0.8770 - val_loss: 0.3943 - val_acc: 0.8410\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2840 - acc: 0.8777 - val_loss: 0.4030 - val_acc: 0.8350\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.2857 - acc: 0.8803 - val_loss: 0.3845 - val_acc: 0.8370\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2849 - acc: 0.8782 - val_loss: 0.3913 - val_acc: 0.8420\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.2885 - acc: 0.8768 - val_loss: 0.3960 - val_acc: 0.8400\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2788 - acc: 0.8794 - val_loss: 0.4449 - val_acc: 0.8300\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2793 - acc: 0.8802 - val_loss: 0.4364 - val_acc: 0.8330\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2806 - acc: 0.8829 - val_loss: 0.4083 - val_acc: 0.8350\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2803 - acc: 0.8780 - val_loss: 0.4272 - val_acc: 0.8340\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2746 - acc: 0.8825 - val_loss: 0.4136 - val_acc: 0.8310\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2807 - acc: 0.8824 - val_loss: 0.4231 - val_acc: 0.8240\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2695 - acc: 0.8828 - val_loss: 0.4225 - val_acc: 0.8330\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2786 - acc: 0.8807 - val_loss: 0.4184 - val_acc: 0.8230\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2719 - acc: 0.8847 - val_loss: 0.4089 - val_acc: 0.8230\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2706 - acc: 0.8832 - val_loss: 0.4579 - val_acc: 0.8260\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2729 - acc: 0.8845 - val_loss: 0.4220 - val_acc: 0.8310\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2707 - acc: 0.8830 - val_loss: 0.4217 - val_acc: 0.8320\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2693 - acc: 0.8860 - val_loss: 0.4485 - val_acc: 0.8380\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.2688 - acc: 0.8821 - val_loss: 0.4337 - val_acc: 0.8320\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.2682 - acc: 0.8875 - val_loss: 0.4440 - val_acc: 0.8300\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.2689 - acc: 0.8857 - val_loss: 0.4402 - val_acc: 0.8320\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.2655 - acc: 0.8870 - val_loss: 0.4398 - val_acc: 0.8380\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.2669 - acc: 0.8863 - val_loss: 0.4386 - val_acc: 0.8290\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.2673 - acc: 0.8865 - val_loss: 0.4755 - val_acc: 0.8380\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2656 - acc: 0.8888 - val_loss: 0.4502 - val_acc: 0.8200\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.2584 - acc: 0.8893 - val_loss: 0.4751 - val_acc: 0.8350\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.2606 - acc: 0.8895 - val_loss: 0.4442 - val_acc: 0.8310\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.2550 - acc: 0.8928 - val_loss: 0.4589 - val_acc: 0.8250\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2588 - acc: 0.8880 - val_loss: 0.4300 - val_acc: 0.8220\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2581 - acc: 0.8903 - val_loss: 0.4570 - val_acc: 0.8230\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2551 - acc: 0.8910 - val_loss: 0.4815 - val_acc: 0.8250\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2559 - acc: 0.8926 - val_loss: 0.4552 - val_acc: 0.8290\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.2573 - acc: 0.8925 - val_loss: 0.4581 - val_acc: 0.8270\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.2493 - acc: 0.8947 - val_loss: 0.4684 - val_acc: 0.8330\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.2534 - acc: 0.8944 - val_loss: 0.4438 - val_acc: 0.8280\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=100,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'chatbot_10.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nglJKqWoaCkoppar9P/A/H30bJpQeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999956\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9398415\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
